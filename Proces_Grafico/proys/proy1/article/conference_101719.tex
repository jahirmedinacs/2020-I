\documentclass[a4paper]{IEEEtranUNT}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{csquotes}
\usepackage{verbatim}

\usepackage{natbib}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,LO]{Universidad Nacional de Trujillo.\
	Medina Jahir, Pastor Christian, Salinas Jhosep, Sifuentes Víctor.\
	Seguridad y Comunicaciones}
\fancyhead[RE,RO]{\thepage}
\fancyfoot[LE,LO]{Tópicos Especiales en Procesamiento Gráfico, \the\year}
\renewcommand{\headrulewidth}{0pt}


\begin{document}

\title{Visión Computacional aplicado en la Seguridad y Comunicaciones\\
%{\footnotesize \textsuperscript{*}Articulo para el curso Tópicos Especiales en Procesamiento Gráfico}
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Medina, Jahir., Pastor, Christian., Salinas, Jhosep y Sifuentes, Víctor.}\\
\IEEEauthorblockA{\textit{\{jahirmedina, cmpastors, jhsalinasg, vsifuentes\}@unitru.edu.pe}\\
	Universidad Nacional de Trujillo}}


\maketitle

\begin{abstract}
La visión computacional como técnica de detección o análisis de patrones , en la actualidad, es una norma. Desde la vigilancia mediante
cámaras de circuito cerrado hasta la eliminación de ruidos en sen\~nales de audio.

La visión computacional ha avanzando hasta un punto donde es capaz de analizar contextos , pudiendo identificar si se comete un delito o
si existe una persona con actitud sospechosa.

Es por esto que en el presente articulo, se hara un recuento de las aplicaciones modernas de la visión computacional. Mas concretamente su
aplicación en el capo de la seguridad , vigilancia y telecomunicaciones.

\end{abstract}

\begin{IEEEkeywords}
Visión Computacional, Seguridad, Seguridad Informática, Vigilancia, Telecomunicaciones, Procesamiento de Se\~nales,
DeepFake.
\end{IEEEkeywords}

\section{Introducción}

Escribir Luego

\section{La vigilancia automatizada}

\subsection{Década de los 90's}

Desde que se empezó a usar de forma comercial tecnologías de procesamiento de imágenes para detectar movimiento en
grabaciones tomadas por Cámaras de Circuito Cerrado \textit{(CCTV , por sus siglas en ingles)} en los a\~nos 80's,
se veía el potencial pero también su mal rendimiento, especialmente por la alta taza de falsos negativos 
en la detección de intrusos \citep{Sage}.

Sin embargo, una solución que se considero y trabajo por mucho tiempo fue la de recopilar mas información para así poder
garantizar la disminución de falsos negativos (Esto Basado en una cuestión estadística, mas información, mejor predicción).

Sin embargo, arrojar hardware a un problema de software es una solución,que a la larga aumenta los costos de cualquier sistema.
Ante esta problemática, se comenzó a plantear modelos estocásticos para no solo detectar variaciones en la escena filmada, sino
para intentar también, trazar una ruta y aproximar este comportamiento a uno próximo de un humano \citep{Sage}.

Gracias a las mejoras en las técnicas de análisis y la mejor calidad en vídeo, en los últimos a\~nos de los 90's , se empezaron
a plantear sistemas de detección en escenarios dinámicas, siendo un caso particular, las carreteras \citep{Manendez}. La motivación,
tal como menciona el paper \textit{Vigilancia de Autopistas mediante visión computacional stereo} \citep[Abstract]{Manendez}
se origina por el aumento de la demanda de automatización, la ubicuidad de cámaras y la mayor necesidad de automatización y abaratamiento
de costos.

En todo este escenario de crecimiento tecnológico, no solo de hardware , sino también de software y sus respectivos algoritmos, es que
comienza a surgir la idea de extender estas aplicaciones a campos mas delicados: Detección de crímenes y Verificación Biometrica.

\subsection{Década de los 2000's}



\section{El Auge de las Redes Neuronales}

\subsection{Las Redes Neuronales, excelentes Clasificadores}
\subsection{Las Redes Convencionales, excelentes Extractores de Características}


\section{Firma Biometrica y Procesamiento Avanzado de Señales}

\subsection{DeepFake y mas formas de suplantación de identidad}

Con el avance de la capacidad de hardware, se volvió mas fácil implementar arquitecturas extremas. 
Estas arquitecturas capaces de procesar \textit{batchs} de mas 10gb empezaron a ser prometedoras en el
ambito de la creacion de informacion artificial, analisis de patrones mas complejos y deteccion de 
caracterizticas jamas pensadas.

\subsection{Espionaje de Vanguardia}

\section{Conclusiones}

\section{Apéndice}


\bibliography{bibfile}
\bibliographystyle{apalike}


\end{document}
